#  TitanicPredict  

##  Modelo de Machine Learning para prever a sobreviv√™ncia dos passageiros do Titanic  

**Dados:** [Kaggle - Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/data)  

Um dos primeiros desafios cl√°ssicos do Kaggle √© o Titanic Survival Prediction, cujo objetivo √© prever se um passageiro sobreviveu ou n√£o ao acidente, com base em informa√ß√µes como classe, idade, sexo, valor da passagem, entre outras vari√°veis.  

A ideia √© treinar um modelo de Machine Learning utilizando os dados de treino e teste fornecidos, gerando uma classifica√ß√£o bin√°ria ‚Äî 1 para sobreviveu, 0 para n√£o sobreviveu.  

Neste projeto, utilizei as bibliotecas NumPy, Pandas e Scikit-Learn, aplicando o modelo Random Forest Classifier para realizar as predi√ß√µes.  

---

##  Etapas do Projeto  

### 1. Importa√ß√£o e Configura√ß√£o Inicial  
Importei as bibliotecas necess√°rias e defini a semente (random_state=0) para padronizar os resultados e garantir reprodutibilidade.  
Em seguida, carreguei os arquivos train.csv e test.csv obtidos no Kaggle, salvando tamb√©m o identificador do passageiro PassengerId para a planilha final de submiss√£o.  

---

### 2. An√°lise das Vari√°veis  
Foi realizada uma an√°lise explorat√≥ria para compreender quais vari√°veis possu√≠am maior influ√™ncia na sobreviv√™ncia.  
As principais escolhidas foram:  

- **Num√©ricas:** Age, Fare (pre√ßo da passagem) e FamilySize (tamanho da fam√≠lia embarcada);  
- **Categ√≥ricas:** Pclass (classe do ticket), Sex, Embarked (porto de embarque), Title (t√≠tulo extra√≠do do nome), Cabin (n√∫mero da cabine) e isAlone (indicador de quem viajava sozinho).  

Busquei um equil√≠brio entre **complexidade e interpretabilidade**, priorizando vari√°veis relevantes e com impacto direto no modelo.  

---

##  Pr√©-processamento  

### üîπ Extra√ß√£o do T√≠tulo (`Title`)  
A coluna Name continha o t√≠tulo do passageiro junto ao nome, separado por v√≠rgula e ponto.  
Foi criada uma fun√ß√£o para **extrair o t√≠tulo** (ex: Mr, Miss, Mrs, Dr).  

Ajustes adicionais:
- Substitu√≠ Mlle e Ms por Miss, e Mme por Mrs;  
- Agrupei t√≠tulos menos comuns na categoria "Rare", incluindo:  
  'Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'.  

### üîπ Cria√ß√£o de Novas Features  
- **FamilySize**: soma de SibSp (irm√£os/c√¥njuges a bordo) + Parch (pais/filhos a bordo) + 1 (o pr√≥prio passageiro).  
- **isAlone**: vari√°vel bin√°ria que indica se o passageiro estava sozinho.  

### üîπ Pipeline de Pr√©-processamento  
Foram criadas **pipelines separadas para vari√°veis num√©ricas e categ√≥ricas**:  
- Num√©ricas: substitui√ß√£o de valores ausentes pela **mediana**;  
- Categ√≥ricas: substitui√ß√£o pela **categoria mais frequente**, seguida de **codifica√ß√£o One-Hot** (OneHotEncoder).  

Essas transforma√ß√µes s√£o aplicadas **apenas em mem√≥ria**, sem modificar os arquivos originais, garantindo consist√™ncia e reprodutibilidade.  

---

##  Modelo de Machine Learning  

Utilizei o **RandomForestClassifier**, um modelo de aprendizado em conjunto (ensemble) composto por v√°rias √°rvores de decis√£o.  
Cada √°rvore realiza previs√µes independentes, e o resultado final √© determinado pelo voto majorit√°rio das √°rvores.  

**Principais par√¢metros utilizados:**
- `n_estimators=100` ‚Üí n√∫mero de √°rvores na floresta;  
- `max_depth=None` ‚Üí profundidade m√°xima das √°rvores (ilimitada);  
- `min_samples_split=2` ‚Üí n√∫mero m√≠nimo de amostras para dividir um n√≥;  
- `random_state=42` ‚Üí garante a reprodutibilidade dos resultados.  

A avalia√ß√£o foi feita com **valida√ß√£o cruzada (Cross-Validation)**, utilizando `StratifiedKFold` com `cv=5` divis√µes.  
Essa t√©cnica permite medir o desempenho do modelo de forma mais confi√°vel, evitando vi√©s causado por um √∫nico corte de treino e teste.  

---

##  Resultados  

- **Acur√°cia na valida√ß√£o cruzada:** ~82%  
- **Acur√°cia na submiss√£o do Kaggle:** 0.77  

Os resultados indicam uma boa capacidade de generaliza√ß√£o do modelo, sem sinais significativos de overfitting.  

---


##  Aprendizados  

Durante o desenvolvimento deste projeto, consolidei conhecimentos sobre:
- Pr√©-processamento de dados (tratamento de nulos e codifica√ß√£o de vari√°veis categ√≥ricas);  
- Cria√ß√£o e manipula√ß√£o de novas features;  
- Aplica√ß√£o e avalia√ß√£o de modelos de classifica√ß√£o supervisionada;  
- Uso de pipelines para um fluxo de tratamento reproduz√≠vel e limpo;  
- Entendimento pr√°tico da valida√ß√£o cruzada e import√¢ncia da reprodutibilidade.  

---

##  Pr√≥ximos Passos  

- Testar outros modelos como **XGBoost**, **Logistic Regression** e **Gradient Boosting**;  
- Otimizar hiperpar√¢metros com **GridSearchCV** ou **Optuna**;  
- Implementar **interpreta√ß√£o do modelo** com SHAP ou LIME;  
- Criar um **dashboard interativo** para visualiza√ß√£o das previs√µes.  

---
